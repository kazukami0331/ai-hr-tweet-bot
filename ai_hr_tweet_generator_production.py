#!/usr/bin/env python3
import os
import json
import requests
from datetime import datetime
import anthropic

# Google Apps Script URL
SPREADSHEET_WEBHOOK = "https://script.google.com/macros/s/AKfycbxaAwqsszgBeOcuacwN9I54z9YtRzapVK1yUNLC9WCBThRVQKiisdqOZh8EjSHeJa8h/exec"

SEARCH_QUERIES = [
    "AI Agent æ¡ç”¨ äººæ 2025",
    "AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ äººäº‹ HR",
    "æ¡ç”¨AI è‡ªå‹•åŒ– æœ€æ–°",
]

PROMPT = """
ã‚ãªãŸã¯ã€ŒAIÃ—æ¡ç”¨ã€é ˜åŸŸã®å°‚é–€å®¶ã¨ã—ã¦ã€Xã§ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã®é«˜ã„æŠ•ç¨¿ã‚’ä½œæˆã™ã‚‹ãƒ—ãƒ­ã§ã™ã€‚

ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰æœ€ã‚‚ãƒã‚ºã‚Šãã†ãªã‚‚ã®ã‚’1ã¤é¸ã³ã€æŠ•ç¨¿ã‚’3ãƒ‘ã‚¿ãƒ¼ãƒ³ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§
{news_json}

## Xã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆï¼ˆ2025å¹´æœ€æ–°ï¼‰
- çŸ­æ–‡ã‚„ä¸€æ–‡ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚Œãªã„
- é«˜åŠ´åŠ›ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å„ªå…ˆ
â†’ ã€Œé‡ã‚ˆã‚Šè³ªã€ã€ŒçŸ­æ–‡ã‚ˆã‚Šé•·æ–‡ã€ãŒæ­£è§£

## æŠ•ç¨¿ä½œæˆãƒ«ãƒ¼ãƒ«
1. æ–‡å­—æ•°: 500ã€œ1000æ–‡å­—ç¨‹åº¦
2. æ§‹æˆ: å†’é ­ãƒ•ãƒƒã‚¯ â†’ æœ¬æ–‡ãƒ»è€ƒå¯Ÿ â†’ èª­è€…ã¸ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ â†’ å…ƒãƒã‚¿URL
3. å…·ä½“çš„ãªæ•°å­—ã‚’å…¥ã‚Œã‚‹ï¼ˆã‚½ãƒ¼ã‚¹ã«ãªã„æ•°å­—ã¯ä½¿ã‚ãªã„ï¼‰
4. ç‹¬è‡ªã®è¦–ç‚¹ã‚’åŠ ãˆã‚‹ï¼ˆãªãœé‡è¦ã‹ã€å½±éŸ¿äºˆæ¸¬ã€å–ã‚‹ã¹ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
5. é©åº¦ã«æ”¹è¡Œã€ç®‡æ¡æ›¸ãã‚‚å¯
6. ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã¯æœ€å¤§2ã¤
7. ã€Œç§ã€ã€Œå¼Šç¤¾ã€ã¯ä½¿ã‚ãªã„

## æŠ•ç¨¿è€…ãƒšãƒ«ã‚½ãƒŠ
- AIÃ—æ¡ç”¨é ˜åŸŸã®å°‚é–€å®¶
- è»¢è·è€…å‘ã‘AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚µãƒ¼ãƒ“ã‚¹ã‚’é‹å–¶
- 1,500ä»¶ä»¥ä¸Šã®ã‚­ãƒ£ãƒªã‚¢é¢è«‡å®Ÿç¸¾

## å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰
{{
  "selected_news": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«",
  "selected_news_url": "URL",
  "reason": "é¸ã‚“ã ç†ç”±ï¼ˆ50å­—ä»¥å†…ï¼‰",
  "posts": [
    {{"text": "æŠ•ç¨¿æœ¬æ–‡ï¼ˆæœ«å°¾ã«URLå«ã‚€ï¼‰", "format_type": "ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå", "hook": "å†’é ­ãƒ•ãƒƒã‚¯"}}
  ]
}}
"""

def fetch_news(queries):
    api_key = os.environ.get("TAVILY_API_KEY")
    if not api_key:
        raise ValueError("TAVILY_API_KEY not set")
    
    all_news = []
    seen = set()
    
    for query in queries:
        try:
            r = requests.post("https://api.tavily.com/search", json={
                "api_key": api_key,
                "query": query,
                "search_depth": "advanced",
                "max_results": 5,
                "exclude_domains": ["youtube.com", "twitter.com", "x.com"]
            })
            r.raise_for_status()
            for item in r.json().get("results", []):
                if item["url"] not in seen:
                    seen.add(item["url"])
                    all_news.append({
                        "title": item.get("title", ""),
                        "summary": item.get("content", "")[:300],
                        "url": item.get("url", "")
                    })
        except Exception as e:
            print(f"âš ï¸ Search error: {e}")
    
    return all_news[:10]

def generate_posts(news):
    client = anthropic.Anthropic()
    prompt = PROMPT.format(news_json=json.dumps(news, ensure_ascii=False, indent=2))
    
    msg = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=4000,
        messages=[{"role": "user", "content": prompt}]
    )
    
    text = msg.content[0].text
    if "```json" in text:
        text = text.split("```json")[1].split("```")[0]
    else:
        text = text[text.find("{"):text.rfind("}")+1]
    
    return json.loads(text)

def send_to_spreadsheet(result):
    """çµæœã‚’Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«é€ä¿¡"""
    posts = result.get("posts", [])
    
    data = {
        "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "selected_news": result.get("selected_news", ""),
        "selected_news_url": result.get("selected_news_url", ""),
        "reason": result.get("reason", ""),
        "post1": posts[0].get("text", "") if len(posts) > 0 else "",
        "post2": posts[1].get("text", "") if len(posts) > 1 else "",
        "post3": posts[2].get("text", "") if len(posts) > 2 else "",
    }
    
    try:
        r = requests.post(SPREADSHEET_WEBHOOK, json=data)
        print(f"âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«é€ä¿¡å®Œäº†")
        print(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {r.text}")
    except Exception as e:
        print(f"âŒ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    print(f"\n{'='*60}")
    print(f"ğŸš€ AIæ¡ç”¨ãƒ‹ãƒ¥ãƒ¼ã‚¹ â†’ æŠ•ç¨¿ç”Ÿæˆ")
    print(f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")
    
    print("ğŸ“¥ ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ä¸­...")
    news = fetch_news(SEARCH_QUERIES)
    print(f"   â†’ {len(news)}ä»¶å–å¾—\n")
    
    if not news:
        print("âŒ ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    for i, n in enumerate(news, 1):
        print(f"   {i}. {n['title'][:50]}...")
    
    print("\nâ³ æŠ•ç¨¿ç”Ÿæˆä¸­...")
    result = generate_posts(news)
    
    print(f"\n{'='*60}")
    print(f"ğŸ“° é¸æŠ: {result.get('selected_news')}")
    print(f"ğŸ”— URL: {result.get('selected_news_url')}")
    print(f"ğŸ’¡ ç†ç”±: {result.get('reason')}")
    print(f"{'='*60}")
    
    for i, post in enumerate(result.get("posts", []), 1):
        print(f"\nã€æ¡ˆ{i}ã€‘{post.get('format_type')}")
        print(f"ãƒ•ãƒƒã‚¯: {post.get('hook')}")
        print("-" * 60)
        print(post.get("text"))
        print(f"\nâ†’ {len(post.get('text', ''))}æ–‡å­—")
    
    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«é€ä¿¡
    print("\nğŸ“¤ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«é€ä¿¡ä¸­...")
    send_to_spreadsheet(result)

if __name__ == "__main__":
    main()
